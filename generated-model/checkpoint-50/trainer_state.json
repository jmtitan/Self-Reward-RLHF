{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.796812749003984,
  "eval_steps": 500,
  "global_step": 50,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.01593625498007968,
      "grad_norm": 0.5712783932685852,
      "learning_rate": 1.0000000000000002e-06,
      "logits/chosen": -0.04936952888965607,
      "logits/rejected": -0.0947456806898117,
      "logps/chosen": -122.98782348632812,
      "logps/rejected": -118.150634765625,
      "loss": 0.6931,
      "rewards/accuracies": 0.0,
      "rewards/chosen": 0.0,
      "rewards/margins": 0.0,
      "rewards/rejected": 0.0,
      "step": 1
    },
    {
      "epoch": 0.03187250996015936,
      "grad_norm": 0.6073831915855408,
      "learning_rate": 2.0000000000000003e-06,
      "logits/chosen": -0.06150328367948532,
      "logits/rejected": 0.05934912711381912,
      "logps/chosen": -136.72254943847656,
      "logps/rejected": -120.11752319335938,
      "loss": 0.6931,
      "rewards/accuracies": 0.0,
      "rewards/chosen": 0.0,
      "rewards/margins": 0.0,
      "rewards/rejected": 0.0,
      "step": 2
    },
    {
      "epoch": 0.04780876494023904,
      "grad_norm": 0.6011028289794922,
      "learning_rate": 3e-06,
      "logits/chosen": -0.024280354380607605,
      "logits/rejected": 0.14555960893630981,
      "logps/chosen": -135.48793029785156,
      "logps/rejected": -111.03228759765625,
      "loss": 0.6931,
      "rewards/accuracies": 0.375,
      "rewards/chosen": 0.00013046264939475805,
      "rewards/margins": 2.765656063274946e-06,
      "rewards/rejected": 0.00012769698514603078,
      "step": 3
    },
    {
      "epoch": 0.06374501992031872,
      "grad_norm": 0.6787139773368835,
      "learning_rate": 4.000000000000001e-06,
      "logits/chosen": -0.130681574344635,
      "logits/rejected": -0.18408548831939697,
      "logps/chosen": -126.47898864746094,
      "logps/rejected": -122.65916442871094,
      "loss": 0.6932,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.00036931040813215077,
      "rewards/margins": -2.1457672119140625e-05,
      "rewards/rejected": 0.00039076805114746094,
      "step": 4
    },
    {
      "epoch": 0.0796812749003984,
      "grad_norm": 0.7282788157463074,
      "learning_rate": 5e-06,
      "logits/chosen": 0.1772056370973587,
      "logits/rejected": 0.21525394916534424,
      "logps/chosen": -126.2254638671875,
      "logps/rejected": -142.54678344726562,
      "loss": 0.6932,
      "rewards/accuracies": 0.375,
      "rewards/chosen": 0.0010120392544195056,
      "rewards/margins": -9.98020259430632e-05,
      "rewards/rejected": 0.001111841294914484,
      "step": 5
    },
    {
      "epoch": 0.09561752988047809,
      "grad_norm": 0.6162426471710205,
      "learning_rate": 6e-06,
      "logits/chosen": 0.04140539839863777,
      "logits/rejected": 0.12258106470108032,
      "logps/chosen": -119.54303741455078,
      "logps/rejected": -122.73192596435547,
      "loss": 0.6932,
      "rewards/accuracies": 0.375,
      "rewards/chosen": 0.0014352441066876054,
      "rewards/margins": -6.80804078001529e-05,
      "rewards/rejected": 0.0015033246017992496,
      "step": 6
    },
    {
      "epoch": 0.11155378486055777,
      "grad_norm": 0.6587119102478027,
      "learning_rate": 7.000000000000001e-06,
      "logits/chosen": -0.09482061862945557,
      "logits/rejected": 0.004695683717727661,
      "logps/chosen": -138.82574462890625,
      "logps/rejected": -121.33673858642578,
      "loss": 0.693,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.0019020556937903166,
      "rewards/margins": 0.00022327303304336965,
      "rewards/rejected": 0.0016787827480584383,
      "step": 7
    },
    {
      "epoch": 0.12749003984063745,
      "grad_norm": 0.6793956160545349,
      "learning_rate": 8.000000000000001e-06,
      "logits/chosen": 0.004228949546813965,
      "logits/rejected": 0.08180402219295502,
      "logps/chosen": -131.8360137939453,
      "logps/rejected": -126.09602355957031,
      "loss": 0.6927,
      "rewards/accuracies": 0.5625,
      "rewards/chosen": 0.0032169341575354338,
      "rewards/margins": 0.0009463309543207288,
      "rewards/rejected": 0.002270603086799383,
      "step": 8
    },
    {
      "epoch": 0.14342629482071714,
      "grad_norm": 0.5095551609992981,
      "learning_rate": 9e-06,
      "logits/chosen": 0.0776790902018547,
      "logits/rejected": 0.1466790735721588,
      "logps/chosen": -111.8860092163086,
      "logps/rejected": -109.3975601196289,
      "loss": 0.6932,
      "rewards/accuracies": 0.3125,
      "rewards/chosen": 0.0037092682905495167,
      "rewards/margins": -2.6130699552595615e-05,
      "rewards/rejected": 0.0037353995721787214,
      "step": 9
    },
    {
      "epoch": 0.1593625498007968,
      "grad_norm": 0.6698275804519653,
      "learning_rate": 1e-05,
      "logits/chosen": 0.20880436897277832,
      "logits/rejected": 0.3403487503528595,
      "logps/chosen": -141.10617065429688,
      "logps/rejected": -134.931640625,
      "loss": 0.6922,
      "rewards/accuracies": 0.4375,
      "rewards/chosen": 0.006038570776581764,
      "rewards/margins": 0.0018488408531993628,
      "rewards/rejected": 0.004189729690551758,
      "step": 10
    },
    {
      "epoch": 0.1752988047808765,
      "grad_norm": 0.5373227596282959,
      "learning_rate": 1.1000000000000001e-05,
      "logits/chosen": -0.0026852376759052277,
      "logits/rejected": 0.15813472867012024,
      "logps/chosen": -120.93324279785156,
      "logps/rejected": -118.232666015625,
      "loss": 0.6931,
      "rewards/accuracies": 0.4375,
      "rewards/chosen": 0.004821872804313898,
      "rewards/margins": 2.7561240131035447e-05,
      "rewards/rejected": 0.004794311709702015,
      "step": 11
    },
    {
      "epoch": 0.19123505976095617,
      "grad_norm": 0.6407908797264099,
      "learning_rate": 1.2e-05,
      "logits/chosen": 0.06783886253833771,
      "logits/rejected": 0.02161625772714615,
      "logps/chosen": -121.93931579589844,
      "logps/rejected": -121.86599731445312,
      "loss": 0.693,
      "rewards/accuracies": 0.4375,
      "rewards/chosen": 0.006415629759430885,
      "rewards/margins": 0.00028000472229905427,
      "rewards/rejected": 0.006135624833405018,
      "step": 12
    },
    {
      "epoch": 0.20717131474103587,
      "grad_norm": 0.6979819536209106,
      "learning_rate": 1.3000000000000001e-05,
      "logits/chosen": 0.13225463032722473,
      "logits/rejected": 0.1148947924375534,
      "logps/chosen": -140.53416442871094,
      "logps/rejected": -142.93905639648438,
      "loss": 0.6941,
      "rewards/accuracies": 0.3125,
      "rewards/chosen": 0.006678867619484663,
      "rewards/margins": -0.0019120695069432259,
      "rewards/rejected": 0.008590937592089176,
      "step": 13
    },
    {
      "epoch": 0.22310756972111553,
      "grad_norm": 0.5965271592140198,
      "learning_rate": 1.4000000000000001e-05,
      "logits/chosen": 0.11964959651231766,
      "logits/rejected": 0.16599752008914948,
      "logps/chosen": -123.75342559814453,
      "logps/rejected": -126.49618530273438,
      "loss": 0.692,
      "rewards/accuracies": 0.5625,
      "rewards/chosen": 0.00978934857994318,
      "rewards/margins": 0.002306294394657016,
      "rewards/rejected": 0.007483053021132946,
      "step": 14
    },
    {
      "epoch": 0.23904382470119523,
      "grad_norm": 0.558516800403595,
      "learning_rate": 1.5e-05,
      "logits/chosen": 0.009343668818473816,
      "logits/rejected": 0.013251702301204205,
      "logps/chosen": -111.46833038330078,
      "logps/rejected": -113.93846130371094,
      "loss": 0.6923,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.007821798324584961,
      "rewards/margins": 0.0017031431198120117,
      "rewards/rejected": 0.006118655204772949,
      "step": 15
    },
    {
      "epoch": 0.2549800796812749,
      "grad_norm": 0.5807020664215088,
      "learning_rate": 1.6000000000000003e-05,
      "logits/chosen": 0.12428490817546844,
      "logits/rejected": 0.042988914996385574,
      "logps/chosen": -126.26596069335938,
      "logps/rejected": -129.539306640625,
      "loss": 0.6934,
      "rewards/accuracies": 0.3125,
      "rewards/chosen": 0.009173202328383923,
      "rewards/margins": -0.0005393744795583189,
      "rewards/rejected": 0.009712576866149902,
      "step": 16
    },
    {
      "epoch": 0.27091633466135456,
      "grad_norm": 0.674453854560852,
      "learning_rate": 1.7000000000000003e-05,
      "logits/chosen": 0.030105140060186386,
      "logits/rejected": 0.034182462841272354,
      "logps/chosen": -126.56507873535156,
      "logps/rejected": -128.23843383789062,
      "loss": 0.6925,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.008892345242202282,
      "rewards/margins": 0.0013817788567394018,
      "rewards/rejected": 0.007510566618293524,
      "step": 17
    },
    {
      "epoch": 0.2868525896414343,
      "grad_norm": 0.5766975283622742,
      "learning_rate": 1.8e-05,
      "logits/chosen": -0.023989353328943253,
      "logits/rejected": -0.021214008331298828,
      "logps/chosen": -127.86517333984375,
      "logps/rejected": -122.31368255615234,
      "loss": 0.6921,
      "rewards/accuracies": 0.375,
      "rewards/chosen": 0.011058425530791283,
      "rewards/margins": 0.0020279884338378906,
      "rewards/rejected": 0.009030437096953392,
      "step": 18
    },
    {
      "epoch": 0.30278884462151395,
      "grad_norm": 0.5147553086280823,
      "learning_rate": 1.9e-05,
      "logits/chosen": -0.03059888631105423,
      "logits/rejected": -0.02939729392528534,
      "logps/chosen": -142.09774780273438,
      "logps/rejected": -125.28829956054688,
      "loss": 0.691,
      "rewards/accuracies": 0.4375,
      "rewards/chosen": 0.018819332122802734,
      "rewards/margins": 0.004420352168381214,
      "rewards/rejected": 0.014398980885744095,
      "step": 19
    },
    {
      "epoch": 0.3187250996015936,
      "grad_norm": 0.5798819661140442,
      "learning_rate": 2e-05,
      "logits/chosen": -0.13873714208602905,
      "logits/rejected": 0.010759854689240456,
      "logps/chosen": -135.73696899414062,
      "logps/rejected": -136.5994415283203,
      "loss": 0.6931,
      "rewards/accuracies": 0.4375,
      "rewards/chosen": 0.01291656494140625,
      "rewards/margins": 0.00019597999926190823,
      "rewards/rejected": 0.012720584869384766,
      "step": 20
    },
    {
      "epoch": 0.3346613545816733,
      "grad_norm": 0.6840194463729858,
      "learning_rate": 2.1e-05,
      "logits/chosen": -0.015086047351360321,
      "logits/rejected": 0.09425434470176697,
      "logps/chosen": -121.84642028808594,
      "logps/rejected": -127.56132507324219,
      "loss": 0.694,
      "rewards/accuracies": 0.3125,
      "rewards/chosen": 0.012704181484878063,
      "rewards/margins": -0.0016563890967518091,
      "rewards/rejected": 0.014360571280121803,
      "step": 21
    },
    {
      "epoch": 0.350597609561753,
      "grad_norm": 0.5065404176712036,
      "learning_rate": 2.2000000000000003e-05,
      "logits/chosen": 0.09580953419208527,
      "logits/rejected": 0.10416057705879211,
      "logps/chosen": -120.22870635986328,
      "logps/rejected": -132.40200805664062,
      "loss": 0.6937,
      "rewards/accuracies": 0.4375,
      "rewards/chosen": 0.0197526216506958,
      "rewards/margins": -0.0009913204703480005,
      "rewards/rejected": 0.020743943750858307,
      "step": 22
    },
    {
      "epoch": 0.3665338645418327,
      "grad_norm": 0.6838206648826599,
      "learning_rate": 2.3000000000000003e-05,
      "logits/chosen": 0.031398747116327286,
      "logits/rejected": 0.0516221858561039,
      "logps/chosen": -129.59896850585938,
      "logps/rejected": -121.19097900390625,
      "loss": 0.6933,
      "rewards/accuracies": 0.375,
      "rewards/chosen": 0.022811315953731537,
      "rewards/margins": -0.00035471946466714144,
      "rewards/rejected": 0.02316603623330593,
      "step": 23
    },
    {
      "epoch": 0.38247011952191234,
      "grad_norm": 0.5718334317207336,
      "learning_rate": 2.4e-05,
      "logits/chosen": 0.0909915491938591,
      "logits/rejected": 0.13492600619792938,
      "logps/chosen": -113.0068359375,
      "logps/rejected": -109.31114196777344,
      "loss": 0.6923,
      "rewards/accuracies": 0.5625,
      "rewards/chosen": 0.018801450729370117,
      "rewards/margins": 0.0016387939685955644,
      "rewards/rejected": 0.017162658274173737,
      "step": 24
    },
    {
      "epoch": 0.398406374501992,
      "grad_norm": 0.6744922399520874,
      "learning_rate": 2.5e-05,
      "logits/chosen": 0.018236398696899414,
      "logits/rejected": -0.08187638968229294,
      "logps/chosen": -130.66595458984375,
      "logps/rejected": -122.48992156982422,
      "loss": 0.6902,
      "rewards/accuracies": 0.4375,
      "rewards/chosen": 0.024384403601288795,
      "rewards/margins": 0.005933570675551891,
      "rewards/rejected": 0.01845083199441433,
      "step": 25
    },
    {
      "epoch": 0.41434262948207173,
      "grad_norm": 0.6568093299865723,
      "learning_rate": 2.6000000000000002e-05,
      "logits/chosen": 0.09895914793014526,
      "logits/rejected": 0.10936117172241211,
      "logps/chosen": -130.7296905517578,
      "logps/rejected": -127.63151550292969,
      "loss": 0.6949,
      "rewards/accuracies": 0.25,
      "rewards/chosen": 0.015349340625107288,
      "rewards/margins": -0.003385305404663086,
      "rewards/rejected": 0.0187346450984478,
      "step": 26
    },
    {
      "epoch": 0.4302788844621514,
      "grad_norm": 0.7104625701904297,
      "learning_rate": 2.7000000000000002e-05,
      "logits/chosen": 0.07360338419675827,
      "logits/rejected": 0.03868579864501953,
      "logps/chosen": -149.37765502929688,
      "logps/rejected": -121.55973815917969,
      "loss": 0.6966,
      "rewards/accuracies": 0.375,
      "rewards/chosen": 0.019296597689390182,
      "rewards/margins": -0.006763161160051823,
      "rewards/rejected": 0.02605975978076458,
      "step": 27
    },
    {
      "epoch": 0.44621513944223107,
      "grad_norm": 0.5511151552200317,
      "learning_rate": 2.8000000000000003e-05,
      "logits/chosen": 0.1078834980726242,
      "logits/rejected": 0.07076825201511383,
      "logps/chosen": -115.68048095703125,
      "logps/rejected": -120.77314758300781,
      "loss": 0.6931,
      "rewards/accuracies": 0.4375,
      "rewards/chosen": 0.0211347583681345,
      "rewards/margins": 0.0001843925565481186,
      "rewards/rejected": 0.02095036581158638,
      "step": 28
    },
    {
      "epoch": 0.46215139442231074,
      "grad_norm": 0.5606430172920227,
      "learning_rate": 2.9e-05,
      "logits/chosen": 0.18844403326511383,
      "logits/rejected": 0.2201661765575409,
      "logps/chosen": -122.07270812988281,
      "logps/rejected": -125.2104721069336,
      "loss": 0.6889,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.03744633495807648,
      "rewards/margins": 0.00865640677511692,
      "rewards/rejected": 0.028789926320314407,
      "step": 29
    },
    {
      "epoch": 0.47808764940239046,
      "grad_norm": 0.6767188310623169,
      "learning_rate": 3e-05,
      "logits/chosen": 0.10209961235523224,
      "logits/rejected": 0.14520156383514404,
      "logps/chosen": -132.28646850585938,
      "logps/rejected": -128.9650115966797,
      "loss": 0.6891,
      "rewards/accuracies": 0.375,
      "rewards/chosen": 0.029874326661229134,
      "rewards/margins": 0.00834274385124445,
      "rewards/rejected": 0.02153158187866211,
      "step": 30
    },
    {
      "epoch": 0.4940239043824701,
      "grad_norm": 0.5521324276924133,
      "learning_rate": 3.1e-05,
      "logits/chosen": -0.05507751554250717,
      "logits/rejected": -0.022190552204847336,
      "logps/chosen": -127.40536499023438,
      "logps/rejected": -123.22319030761719,
      "loss": 0.695,
      "rewards/accuracies": 0.375,
      "rewards/chosen": 0.023236609995365143,
      "rewards/margins": -0.0036072733346372843,
      "rewards/rejected": 0.026843881234526634,
      "step": 31
    },
    {
      "epoch": 0.5099601593625498,
      "grad_norm": 0.6362606883049011,
      "learning_rate": 3.2000000000000005e-05,
      "logits/chosen": 0.1254356950521469,
      "logits/rejected": 0.21350954473018646,
      "logps/chosen": -130.81370544433594,
      "logps/rejected": -124.34828186035156,
      "loss": 0.6898,
      "rewards/accuracies": 0.375,
      "rewards/chosen": 0.02825922891497612,
      "rewards/margins": 0.007090759929269552,
      "rewards/rejected": 0.02116847038269043,
      "step": 32
    },
    {
      "epoch": 0.5258964143426295,
      "grad_norm": 0.6688992381095886,
      "learning_rate": 3.3e-05,
      "logits/chosen": -0.06490734219551086,
      "logits/rejected": -0.049584418535232544,
      "logps/chosen": -142.0302734375,
      "logps/rejected": -136.76980590820312,
      "loss": 0.693,
      "rewards/accuracies": 0.375,
      "rewards/chosen": 0.02996349334716797,
      "rewards/margins": 0.00037460343446582556,
      "rewards/rejected": 0.029588891193270683,
      "step": 33
    },
    {
      "epoch": 0.5418326693227091,
      "grad_norm": 0.5923624038696289,
      "learning_rate": 3.4000000000000007e-05,
      "logits/chosen": 0.1280289590358734,
      "logits/rejected": 0.16029924154281616,
      "logps/chosen": -122.16752624511719,
      "logps/rejected": -128.338134765625,
      "loss": 0.6917,
      "rewards/accuracies": 0.375,
      "rewards/chosen": 0.03223919868469238,
      "rewards/margins": 0.0031505590304732323,
      "rewards/rejected": 0.029088640585541725,
      "step": 34
    },
    {
      "epoch": 0.5577689243027888,
      "grad_norm": 0.6636107563972473,
      "learning_rate": 3.5e-05,
      "logits/chosen": -0.06137558072805405,
      "logits/rejected": -0.09251812845468521,
      "logps/chosen": -133.77230834960938,
      "logps/rejected": -120.13734436035156,
      "loss": 0.7002,
      "rewards/accuracies": 0.375,
      "rewards/chosen": 0.015153074637055397,
      "rewards/margins": -0.013393545523285866,
      "rewards/rejected": 0.028546620160341263,
      "step": 35
    },
    {
      "epoch": 0.5737051792828686,
      "grad_norm": 0.5760794878005981,
      "learning_rate": 3.6e-05,
      "logits/chosen": 0.021855900064110756,
      "logits/rejected": -0.03520504757761955,
      "logps/chosen": -128.2518310546875,
      "logps/rejected": -120.32621002197266,
      "loss": 0.6961,
      "rewards/accuracies": 0.4375,
      "rewards/chosen": 0.031092144548892975,
      "rewards/margins": -0.005686212331056595,
      "rewards/rejected": 0.03677835315465927,
      "step": 36
    },
    {
      "epoch": 0.5896414342629482,
      "grad_norm": 0.6834293603897095,
      "learning_rate": 3.7e-05,
      "logits/chosen": -0.06767318397760391,
      "logits/rejected": -0.0450274758040905,
      "logps/chosen": -105.6996078491211,
      "logps/rejected": -117.67146301269531,
      "loss": 0.694,
      "rewards/accuracies": 0.5625,
      "rewards/chosen": 0.020180417224764824,
      "rewards/margins": -0.0014770025154575706,
      "rewards/rejected": 0.021657418459653854,
      "step": 37
    },
    {
      "epoch": 0.6055776892430279,
      "grad_norm": 0.6807901263237,
      "learning_rate": 3.8e-05,
      "logits/chosen": 0.0038064755499362946,
      "logits/rejected": 0.02025541290640831,
      "logps/chosen": -126.41981506347656,
      "logps/rejected": -125.90249633789062,
      "loss": 0.6831,
      "rewards/accuracies": 0.5625,
      "rewards/chosen": 0.04833097755908966,
      "rewards/margins": 0.020403338596224785,
      "rewards/rejected": 0.027927637100219727,
      "step": 38
    },
    {
      "epoch": 0.6215139442231076,
      "grad_norm": 0.5876339673995972,
      "learning_rate": 3.9000000000000006e-05,
      "logits/chosen": 0.10571560263633728,
      "logits/rejected": 0.11615493893623352,
      "logps/chosen": -117.8569564819336,
      "logps/rejected": -112.77033996582031,
      "loss": 0.6901,
      "rewards/accuracies": 0.5625,
      "rewards/chosen": 0.024149108678102493,
      "rewards/margins": 0.006103205494582653,
      "rewards/rejected": 0.018045902252197266,
      "step": 39
    },
    {
      "epoch": 0.6374501992031872,
      "grad_norm": 0.6129869818687439,
      "learning_rate": 4e-05,
      "logits/chosen": -0.02707628160715103,
      "logits/rejected": 0.059470124542713165,
      "logps/chosen": -132.085693359375,
      "logps/rejected": -136.75494384765625,
      "loss": 0.6944,
      "rewards/accuracies": 0.3125,
      "rewards/chosen": 0.028467442840337753,
      "rewards/margins": -0.002367615234106779,
      "rewards/rejected": 0.03083505667746067,
      "step": 40
    },
    {
      "epoch": 0.6533864541832669,
      "grad_norm": 0.7281897664070129,
      "learning_rate": 4.1e-05,
      "logits/chosen": 0.036189328879117966,
      "logits/rejected": 0.04760490357875824,
      "logps/chosen": -134.89291381835938,
      "logps/rejected": -131.0916748046875,
      "loss": 0.6932,
      "rewards/accuracies": 0.375,
      "rewards/chosen": 0.03874821588397026,
      "rewards/margins": -2.551102079451084e-05,
      "rewards/rejected": 0.03877372667193413,
      "step": 41
    },
    {
      "epoch": 0.6693227091633466,
      "grad_norm": 0.7439594864845276,
      "learning_rate": 4.2e-05,
      "logits/chosen": 0.09751724451780319,
      "logits/rejected": 0.08708155155181885,
      "logps/chosen": -124.48328399658203,
      "logps/rejected": -116.89025115966797,
      "loss": 0.697,
      "rewards/accuracies": 0.3125,
      "rewards/chosen": 0.010801887139678001,
      "rewards/margins": -0.007353615947067738,
      "rewards/rejected": 0.018155504018068314,
      "step": 42
    },
    {
      "epoch": 0.6852589641434262,
      "grad_norm": 0.6513546109199524,
      "learning_rate": 4.3e-05,
      "logits/chosen": -0.03756161779165268,
      "logits/rejected": -0.0007649604231119156,
      "logps/chosen": -131.19410705566406,
      "logps/rejected": -120.577880859375,
      "loss": 0.6877,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.050706006586551666,
      "rewards/margins": 0.011186028830707073,
      "rewards/rejected": 0.03951997309923172,
      "step": 43
    },
    {
      "epoch": 0.701195219123506,
      "grad_norm": 0.670637309551239,
      "learning_rate": 4.4000000000000006e-05,
      "logits/chosen": -0.13571789860725403,
      "logits/rejected": -0.08180103451013565,
      "logps/chosen": -128.20849609375,
      "logps/rejected": -136.12010192871094,
      "loss": 0.6967,
      "rewards/accuracies": 0.375,
      "rewards/chosen": 0.03542046621441841,
      "rewards/margins": -0.006909752264618874,
      "rewards/rejected": 0.042330220341682434,
      "step": 44
    },
    {
      "epoch": 0.7171314741035857,
      "grad_norm": 0.6950199007987976,
      "learning_rate": 4.5e-05,
      "logits/chosen": 0.097537562251091,
      "logits/rejected": 0.16174346208572388,
      "logps/chosen": -112.29363250732422,
      "logps/rejected": -116.19154357910156,
      "loss": 0.6885,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.022696686908602715,
      "rewards/margins": 0.00970158539712429,
      "rewards/rejected": 0.012995099648833275,
      "step": 45
    },
    {
      "epoch": 0.7330677290836654,
      "grad_norm": 0.7149171233177185,
      "learning_rate": 4.600000000000001e-05,
      "logits/chosen": 0.021831609308719635,
      "logits/rejected": 0.04435645416378975,
      "logps/chosen": -133.2543182373047,
      "logps/rejected": -120.83555603027344,
      "loss": 0.6867,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.05667858570814133,
      "rewards/margins": 0.013468028046190739,
      "rewards/rejected": 0.043210554867982864,
      "step": 46
    },
    {
      "epoch": 0.749003984063745,
      "grad_norm": 1.7090116739273071,
      "learning_rate": 4.7e-05,
      "logits/chosen": -0.030993454158306122,
      "logits/rejected": 0.00528392568230629,
      "logps/chosen": -114.89053344726562,
      "logps/rejected": -128.01983642578125,
      "loss": 0.6904,
      "rewards/accuracies": 0.375,
      "rewards/chosen": 0.029886746779084206,
      "rewards/margins": 0.005909825209528208,
      "rewards/rejected": 0.023976922035217285,
      "step": 47
    },
    {
      "epoch": 0.7649402390438247,
      "grad_norm": 0.6038801670074463,
      "learning_rate": 4.8e-05,
      "logits/chosen": 0.017534837126731873,
      "logits/rejected": 0.004459291696548462,
      "logps/chosen": -125.55142211914062,
      "logps/rejected": -121.61780548095703,
      "loss": 0.6842,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.04695132002234459,
      "rewards/margins": 0.01818826235830784,
      "rewards/rejected": 0.0287630558013916,
      "step": 48
    },
    {
      "epoch": 0.7808764940239044,
      "grad_norm": 0.5758589506149292,
      "learning_rate": 4.9e-05,
      "logits/chosen": -0.03764845430850983,
      "logits/rejected": 0.021232575178146362,
      "logps/chosen": -121.52363586425781,
      "logps/rejected": -112.9298324584961,
      "loss": 0.6918,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.054710544645786285,
      "rewards/margins": 0.002810894511640072,
      "rewards/rejected": 0.05189964920282364,
      "step": 49
    },
    {
      "epoch": 0.796812749003984,
      "grad_norm": 0.7520469427108765,
      "learning_rate": 5e-05,
      "logits/chosen": -0.0994536280632019,
      "logits/rejected": -0.05925646796822548,
      "logps/chosen": -129.86709594726562,
      "logps/rejected": -132.81765747070312,
      "loss": 0.6883,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": 0.055265288800001144,
      "rewards/margins": 0.010847711935639381,
      "rewards/rejected": 0.044417575001716614,
      "step": 50
    }
  ],
  "logging_steps": 1,
  "max_steps": 62,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 50,
  "total_flos": 0.0,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
